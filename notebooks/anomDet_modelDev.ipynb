{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.dates import DateFormatter\n",
    "import os\n",
    "import joblib\n",
    "from scipy.stats import median_abs_deviation\n",
    "from skyfield.api import load, EarthSatellite\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\prod_code')\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\dataout_HPC\\model_test_train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2544"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_ids = df['NORAD_CAT_ID'].unique()\n",
    "unique_ids.sort()\n",
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model...\n",
      "Initializing detector with input_dim=6, latent_dim=4\n",
      "Using device: cpu\n",
      "Starting training with data shape: (2918, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m anom_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manom_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m all_orbital_features]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m count, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_ids, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 32\u001b[0m     orb_df, detector, anomalies, explanations, samp_df \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_anom_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     anom_dict \u001b[38;5;241m=\u001b[39m {exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_index\u001b[39m\u001b[38;5;124m'\u001b[39m]: [feat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manomalous_features\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m explanations}    \n\u001b[0;32m     36\u001b[0m     full_df \u001b[38;5;241m=\u001b[39m samp_df\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[45], line 14\u001b[0m, in \u001b[0;36mbuild_anom_model\u001b[1;34m(NORAD_ID_NUM)\u001b[0m\n\u001b[0;32m     10\u001b[0m plot_save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdk412\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDavid\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPython Projects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRusSat\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtraining_plots\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mplots_training_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNORAD_ID_NUM\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(orb_df)\n\u001b[1;32m---> 14\u001b[0m detector, anomalies, explanations, timestamps, anomaly_details \u001b[38;5;241m=\u001b[39m \u001b[43mrun_anomaly_detection_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43morb_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdk412\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDavid\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPython Projects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mRusSat\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43manomaly_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshould_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNORAD_ID_NUM\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNORAD_ID_NUM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_save_dir\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m orb_df, detector, anomalies, explanations, samp_df\n",
      "File \u001b[1;32m~\\Desktop\\David\\Python Projects\\RusSat\\prod_code\\helpers.py:459\u001b[0m, in \u001b[0;36mrun_anomaly_detection_pipeline\u001b[1;34m(df, feature_names, model_path, should_train, NORAD_ID_NUM, plot_save_dir)\u001b[0m\n\u001b[0;32m    456\u001b[0m timestamps \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m    457\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_train:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining new model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    461\u001b[0m     detector \u001b[38;5;241m=\u001b[39m TLEAnomalyDetector(input_dim\u001b[38;5;241m=\u001b[39minput_dim)\n",
      "File \u001b[1;32m~\\Desktop\\David\\Python Projects\\RusSat\\prod_code\\helpers.py:352\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, data, epochs, batch_size)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training with data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input_data(data)\n\u001b[1;32m--> 352\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[0;32m    353\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(scaled_data)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    355\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m    356\u001b[0m                      \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mparameters()))\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\optim\\adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\optim\\optimizer.py:278\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    275\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allowed_functions, convert_frame, eval_frame, resume_execution\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:45\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     34\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     transform_code_object,\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_size\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     CacheSizeRelevantForFrame,\n\u001b[0;32m     41\u001b[0m     compute_cache_size,\n\u001b[0;32m     42\u001b[0m     exceeds_cache_size_limit,\n\u001b[0;32m     43\u001b[0m     is_recompilation,\n\u001b[0;32m     44\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m always_optimize_code_objects, skip_code, TorchPatcher\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     augment_exc_message,\n\u001b[0;32m     48\u001b[0m     BackendCompilerFailed,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     Unsupported,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     CheckFunctionManager,\n\u001b[0;32m     58\u001b[0m     get_and_maybe_log_recompilation_reason,\n\u001b[0;32m     59\u001b[0m     GuardedCode,\n\u001b[0;32m     60\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:69\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39meval_frame, name)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, external_utils, skipfiles, utils\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcode_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m code_context\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CondOpArgsMismatchError, UserError, UserErrorType\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\skipfiles.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_content_store\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     41\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     42\u001b[0m     UserMethodVariable,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mA note on skipfiles:\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03myou don't want to inline them.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m BUILTIN_SKIPLIST \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m     abc,\n\u001b[0;32m     92\u001b[0m     collections,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m     _weakrefset,\n\u001b[0;32m    122\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:26\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     ConstDictVariable,\n\u001b[0;32m     16\u001b[0m     CustomizedDictVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     SetVariable,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     23\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     24\u001b[0m     UserMethodVariable,\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhigher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TorchHigherOrderOperatorVariable\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     CountIteratorVariable,\n\u001b[0;32m     29\u001b[0m     CycleIteratorVariable,\n\u001b[0;32m     30\u001b[0m     IteratorVariable,\n\u001b[0;32m     31\u001b[0m     RepeatIteratorVariable,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyVariableTracker\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\_dynamo\\variables\\higher_order_ops.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_python_dispatcher\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy_to_fake_tensor, get_fake_value, get_real_value\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\onnx\\__init__.py:46\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckerError  \u001b[38;5;66;03m# Backwards compatibility\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     _optimize_graph,\n\u001b[0;32m     36\u001b[0m     _run_symbolic_function,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     unregister_custom_op_symbolic,\n\u001b[0;32m     44\u001b[0m )\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort:skip. needs to be last to avoid circular import\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     DiagnosticOptions,\n\u001b[0;32m     48\u001b[0m     ExportOptions,\n\u001b[0;32m     49\u001b[0m     ONNXProgram,\n\u001b[0;32m     50\u001b[0m     ONNXProgramSerializer,\n\u001b[0;32m     51\u001b[0m     ONNXRuntimeOptions,\n\u001b[0;32m     52\u001b[0m     InvalidExportOptionsError,\n\u001b[0;32m     53\u001b[0m     OnnxExporterError,\n\u001b[0;32m     54\u001b[0m     OnnxRegistry,\n\u001b[0;32m     55\u001b[0m     dynamo_export,\n\u001b[0;32m     56\u001b[0m     enable_fake_mode,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnxruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     is_onnxrt_backend_supported,\n\u001b[0;32m     61\u001b[0m     OrtBackend \u001b[38;5;28;01mas\u001b[39;00m _OrtBackend,\n\u001b[0;32m     62\u001b[0m     OrtBackendOptions \u001b[38;5;28;01mas\u001b[39;00m _OrtBackendOptions,\n\u001b[0;32m     63\u001b[0m     OrtExecutionProvider \u001b[38;5;28;01mas\u001b[39;00m _OrtExecutionProvider,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Modules\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbolic_helper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_onnxrt_backend_supported\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\onnx\\_internal\\exporter.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _beartype, io_adapter\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiagnostics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infra\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     decomposition_table,\n\u001b[0;32m     46\u001b[0m     patcher \u001b[38;5;28;01mas\u001b[39;00m patcher,\n\u001b[0;32m     47\u001b[0m     registration,\n\u001b[0;32m     48\u001b[0m     serialization \u001b[38;5;28;01mas\u001b[39;00m fx_serialization,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# We can only import onnx from this module in a type-checking context to ensure that\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# 'import torch.onnx' continues to work without having 'onnx' installed. We fully\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# 'import onnx' inside of dynamo_export (by way of _assert_dependencies).\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\onnx\\_internal\\fx\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ONNXTorchPatcher\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_model_with_external_data\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_model_with_external_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONNXTorchPatcher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\torch\\onnx\\_internal\\fx\\patcher.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# TODO: Remove after https://github.com/huggingface/safetensors/pull/318\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# safetensors is not an exporter requirement, but needed for some huggingface models\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]  # noqa: F401\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m torch \u001b[38;5;28;01mas\u001b[39;00m safetensors_torch  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dk412\\.conda\\envs\\satdet_env\\lib\\site-packages\\safetensors\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Re-export this\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_safetensors_rust\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     SafetensorError,\n\u001b[0;32m      4\u001b[0m     __version__,\n\u001b[0;32m      5\u001b[0m     deserialize,\n\u001b[0;32m      6\u001b[0m     safe_open,\n\u001b[0;32m      7\u001b[0m     serialize,\n\u001b[0;32m      8\u001b[0m     serialize_file,\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def build_anom_model(NORAD_ID_NUM):\n",
    "\n",
    "    os.makedirs(rf\"C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\output\\training_plots\\plots_training_{NORAD_ID_NUM}\", exist_ok=True)\n",
    "\n",
    "    samp_df = df[df['NORAD_CAT_ID']==NORAD_ID_NUM]\n",
    "    samp_df = samp_df.sort_values(by='datetime', ascending=False)\n",
    "    orb_df = samp_df[['datetime','inclination','ra_of_asc_node', 'eccentricity', 'arg_of_perigee', 'mean_anomaly', 'mean_motion']]\n",
    "    orb_df = orb_df.set_index('datetime', drop = True)\n",
    "    \n",
    "    plot_save_dir = rf\"C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\output\\training_plots\\plots_training_{NORAD_ID_NUM}\"\n",
    "    \n",
    "    feature_names = list(orb_df)\n",
    "    \n",
    "    detector, anomalies, explanations, timestamps, anomaly_details = run_anomaly_detection_pipeline(\n",
    "        orb_df,\n",
    "        feature_names=feature_names,\n",
    "        model_path=r\"C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\anomaly_model\",\n",
    "        should_train=True,\n",
    "        NORAD_ID_NUM=NORAD_ID_NUM,  \n",
    "        plot_save_dir=plot_save_dir  \n",
    "    )\n",
    "    \n",
    "    return orb_df, detector, anomalies, explanations, samp_df   \n",
    "\n",
    "unique_ids = df['NORAD_CAT_ID'].unique()[:5]\n",
    "total_sats = len(unique_ids)\n",
    "\n",
    "all_orbital_features = ['inclination', 'ra_of_asc_node', 'eccentricity', 'arg_of_perigee', 'mean_anomaly', 'mean_motion']\n",
    "anom_columns = [f'anom_{feat}' for feat in all_orbital_features]\n",
    "\n",
    "for count, x in enumerate(unique_ids, 1):\n",
    "    orb_df, detector, anomalies, explanations, samp_df = build_anom_model(x)\n",
    "    \n",
    "    anom_dict = {exp['sample_index']: [feat['feature'] for feat in exp['anomalous_features']] for exp in explanations}    \n",
    "\n",
    "    full_df = samp_df.copy(deep=False)\n",
    "    full_df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "    all_features = set().union(*[set(features) for features in anom_dict.values()]) \n",
    "    \n",
    "    anom_df = pd.DataFrame(0, \n",
    "                        index=anom_dict.keys(),\n",
    "                        columns=anom_columns)\n",
    "\n",
    "    for key, features in anom_dict.items():\n",
    "        anom_df.loc[key, [f'anom_{feat}' for feat in features]] = 1\n",
    "\n",
    "    full_df = full_df.join(anom_df, how='left')\n",
    "\n",
    "    full_df['anom_count'] = full_df.filter(like='anom_').sum(axis=1)\n",
    "    full_df = full_df.fillna(0)\n",
    "\n",
    "    for col in anom_columns:\n",
    "        if col not in full_df.columns:\n",
    "            full_df[col] = 0\n",
    "\n",
    "    mode = 'w' if count == 1 else 'a'\n",
    "    header = count == 1\n",
    "    full_df.to_csv(r'C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\output\\anom_df_TRAIN_all_sats.csv', mode=mode, header=header, index=False)\n",
    "    \n",
    "    progress = count/df['NORAD_CAT_ID'].nunique()*100\n",
    "    print(f\"\\nModel number {count} out of {df['NORAD_CAT_ID'].nunique()} complete. Progress: {progress:.3f}% done\\n\")\n",
    "\n",
    "    del full_df, orb_df, detector, anomalies, explanations, samp_df\n",
    "    del anom_df, anom_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************ WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(r\"C:\\Users\\dk412\\Desktop\\David\\Python Projects\\RusSat\\anomaly_model\")\n",
    "\n",
    "trained = list({int(f.split(\"_\")[0].strip(\"'\\\"\")) for f in files})\n",
    "sat = df['NORAD_CAT_ID'].unique().tolist()\n",
    "\n",
    "sats_to_train = list(set(sat) - set(trained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total satellites: 2544\n",
      "Already trained: 5\n",
      "Need training: 2539\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total satellites: {len(sat)}\")\n",
    "print(f\"Already trained: {len(trained)}\")\n",
    "print(f\"Need training: {len(sats_to_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8195, 16393, 16396, 16397, 16398, 32782, 16402, 16404, 16408, 16409]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sats_to_train[:10]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.insert(0,51511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51511, 8195, 16393, 16396, 16397, 16398, 32782, 16402, 16404, 16408, 16409]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satdet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
